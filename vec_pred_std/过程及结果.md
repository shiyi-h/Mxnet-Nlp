## 字段选取
- 特征
  - 主组名称 分组名称 零件名称
- 目标
  - 标准名称

## 数据制作
- 两份数据集
  1. 单纯使用jieba分词
  2. 用户自定义分词(相当于将所有无用的词语, 只保留有用的词语, 但是不完善)
- 样本不均匀处理
  1. 简单地随机采用样本类别少的样本填充至均匀(由于时间问题, 目前只采用这种方式)
  2. 随机上采样复制填充一部分, 人为增补样本一部分(为名称添加随机干扰的无用字或错别字), 
  注意人为增补比例不宜过多, 这样不容易产生偏离

## 模型
- Bert
  1. 将主组名称,分组名称,零件名称拼接起来当做一句话, 输入到Bert模型中, 
  由于bert模型过大, 且需要庞大的语料库训练, 因此采用预训练的模型, 
  因为只选取了中文的零件名称, bert预训练中支持中文的模型为bert_12_768_12,
  因此采用bert_12_768_12, 数据集采用wiki_multilingual_cased(既有中文也有英文)
  2. 数据集使用K折交叉验证方法分成5分, 第k份验证集的训练集为其他k-1份的数据集
  3. 在Bert的基础上, 尝试了纯Bert, Bert+DPCNN, Bert+LSTM, Bert+LSTMCNN, 
  Bert+TextCNN, Bert+TextDPCNN, Bert+TextIncDPCNN七个模型, 训练集准确率均达92%以上
  4. 模型的评估标准, 因为只关注是否分类正确, 所以评估标准只使用准确率
    - 纯Bert
      - 在Bert模型输出词向量后接上全连接层预测分类, 效果最佳, 验证集的准确率最高达0.849
    - Bert+DPCNN
      - 在Bert模型输出词向量后接上DPCNN模型, 验证集准确率0.816
    - Bert+LSTM
      - 在Bert模型输出词向量后接上双向LSTM模型, 验证集准确率0.847
    - Bert+LSTMCNN
      - 在Bert模型输出词向量后接上LSTMCNN模型, 验证集准确率0.844
    - Bert+TextCNN
      - 在Bert模型输出词向量后接上TextCNN模型, 验证集准确率0.844
    - Bert+TextDPCNN
      - 在Bert模型输出词向量后接上TextDPCNN模型, 验证集准确率0.848
    - Bert+TextIncDPCNN
      - 在Bert模型输出词向量后接上TextIncDPCNN模型, 验证集准确率0.848
- Word2vec
  1. 将主组名称, 分组名称, 零件名称, 标准名称分词后连接成一句话, 
  采用FastText训练词向量
  2. 数据集使用K折交叉验证方法分成5分, 第k份验证集的训练集为其他k-1份的数据集
  3. 训练好词向量后, 用embedding层嵌入词向量, 之后接上DPCNN, LSTM, LSTMCNN, 
  TextCNN, TextDPCNN, TextIncDPCNN六个模型, 其中TextIncDPCNN模型最佳, 
  与Bert相差不是很大

## 简单总结
- 若采用Bert, 则无需再Bert之后接其他模型, 因为Bert模型已经很大, 足够优异
- 若采用Word2vec, 效果的好坏最主要在于词向量训练的部分
- 由于时间问题, 没有给每个模型都调个最优参, 可能结果有所偏差
- 若模型一直训练下去, 会发生过拟合, 已加入丢弃层和正则参数以及BatchNorm层, 
但还是过拟合, 时间问题也没有深究
- 模型的泛化能力较差, 在随机给定一部分样本的情况下, 准确率就百分之五六十左右